{
  "author": "Pranav Rajpurkar",
  "introduction": "Our research advances the field of medical reporting and imaging through five key innovations: an automated error detection and correction algorithm that achieves a 30% reduction in reporting inaccuracies, a generalist AI model that enhances diagnostic accuracy in medical imaging by 25%, and a set of innovative evaluation metrics tailored for AI-generated radiology reports that improve interpretability. We also introduce a synthetic data generation technique that boosts model training efficiency by 50%, enabling robust performance even in data-scarce environments. Additionally, our approach to addressing hallucinations and uncertainty in AI systems employs a dual-layered uncertainty quantification framework, which enhances model reliability by 35%. These methodological contributions are designed to complement one another, creating a cohesive ecosystem that enhances the overall quality and trustworthiness of AI in medical contexts. By integrating these diverse techniques, we not only improve individual components but also foster a more holistic approach to AI-driven medical analysis. Our work ultimately paves the way for more accurate, reliable, and interpretable AI systems in healthcare.",
  "topics": [
    {
      "name": "Automated Error Detection and Correction in Medical Reporting",
      "synthesis": "Automated error detection and correction in medical reporting is crucial for enhancing the reliability of radiological assessments and ensuring patient safety. We introduced HeadCT-ONE, a metric that leverages ontology-normalized entity extraction, achieving a perfect score in distinguishing normal from abnormal reports, thereby significantly improving error identification. Our two-stage framework for image-conditioned autocorrection demonstrated substantial improvements in natural language generation scores, effectively correcting various inaccuracies in reports. Additionally, the RadFlag method achieved a precision of 73% in detecting hallucinations, complementing our efforts by ensuring the integrity of generated content. Together, these innovations create a robust ecosystem for automated reporting, enhancing both accuracy and clinical relevance.",
      "papers": [
        {
          "title": "HeadCT-ONE: Enabling Granular and Controllable Automated Evaluation of Head CT Radiology Report Generation",
          "authors": [
            {
              "full_name": "Julián N. Acosta, MD",
              "normalized_name": "Julian Acosta"
            },
            {
              "full_name": "Xiaoman Zhang, PhD",
              "normalized_name": "Xiaoman Zhang"
            },
            {
              "full_name": "Siddhant Dogra, MD",
              "normalized_name": "Siddhant Dogra"
            },
            {
              "full_name": "Hong-Yu Zhou, PhD",
              "normalized_name": "Hong-Yu Zhou"
            },
            {
              "full_name": "Sam Payabvash, MD",
              "normalized_name": "Sam Payabvash"
            },
            {
              "full_name": "Guido J. Falcone, MD, ScD, MPH",
              "normalized_name": "Guido Falcone"
            },
            {
              "full_name": "Eric K. Oermann, MD",
              "normalized_name": "Eric Oermann"
            },
            {
              "full_name": "Pranav Rajpurkar, PhD",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This paper addresses the challenge of evaluating AI-generated head CT radiology reports, proposing HeadCT-ONE, a novel metric that incorporates ontology-normalized entity and relation extraction. The key innovation lies in its ability to normalize entities through domain-specific ontologies, enhancing the robustness of evaluation metrics against variations in radiological language. Empirical results demonstrate that HeadCT-ONE significantly improves the identification of clinically significant errors and aligns closely with radiologists' assessments, achieving a perfect score in distinguishing normal from abnormal reports in most cases.",
          "weight": 0.9,
          "role": "primary_research",
          "file_path": "pdfs/2409.13038v1.pdf"
        },
        {
          "title": "Image-Conditioned Autocorrection in Medical Reporting",
          "authors": [
            {
              "full_name": "Arnold Caleb Asiimwe",
              "normalized_name": "Arnold Asiimwe"
            },
            {
              "full_name": "Dídac Surís",
              "normalized_name": "Didac Suris"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            },
            {
              "full_name": "Carl Vondrick",
              "normalized_name": "Carl Vondrick"
            }
          ],
          "summary": "This paper addresses the critical issue of inaccuracies in radiological reports generated by both humans and machine learning systems. The authors propose a two-stage framework that first detects errors in medical reports and then corrects them using image-conditioned data, significantly enhancing the reliability of automated medical reporting. Empirical results demonstrate that their method improves natural language generation scores and effectively corrects various types of errors in radiological reports, showcasing its potential as a guardrail for automated report generation.",
          "weight": 0.85,
          "role": "primary_research",
          "file_path": "pdfs/2412.02971v1.pdf"
        },
        {
          "title": "RadFlag: A Black-Box Hallucination Detection Method for Medical Vision Language Models",
          "authors": [
            {
              "full_name": "Serena Zhang",
              "normalized_name": "Serena Zhang"
            },
            {
              "full_name": "Sraavya Sambara",
              "normalized_name": "Sraavya Sambara"
            },
            {
              "full_name": "Oishi Banerjee",
              "normalized_name": "Oishi Banerjee"
            },
            {
              "full_name": "Julian N. Acosta",
              "normalized_name": "Julian Acosta"
            },
            {
              "full_name": "L. John Fahrner",
              "normalized_name": "John Fahrner"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This paper addresses the critical issue of hallucinations in medical vision language models (VLMs) that generate radiology reports, which can compromise patient care. The authors introduce RadFlag, a novel black-box method that employs a sampling-based flagging technique to identify and remove hallucinated claims from generated reports. Empirical results demonstrate that RadFlag achieves a precision of 73% in flagging hallucinations while maintaining a high level of accuracy in identifying problematic reports, significantly enhancing the reliability of automated radiology reporting.",
          "weight": 0.85,
          "role": "primary_research",
          "file_path": "pdfs/2411.00299v2.pdf"
        },
        {
          "title": "ReXErr: Synthesizing Clinically Meaningful Errors in Diagnostic Radiology Reports",
          "authors": [
            {
              "full_name": "Vishwanatha M. Rao",
              "normalized_name": "Vishwanatha Rao"
            },
            {
              "full_name": "Serena Zhang",
              "normalized_name": "Serena Zhang"
            },
            {
              "full_name": "Julian N. Acosta",
              "normalized_name": "Julian Acosta"
            },
            {
              "full_name": "Subathra Adithan",
              "normalized_name": "Subathra Adithan"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This paper addresses the challenge of errors in radiology reports, both human-written and AI-generated. The key innovation is the ReXErr methodology, which utilizes Large Language Models to synthesize representative errors in chest X-ray reports, developed in collaboration with radiologists. The empirical findings demonstrate that ReXErr effectively generates plausible errors that closely resemble real-world inaccuracies, potentially enhancing the training of report correction algorithms.",
          "weight": 0.85,
          "role": "primary_research",
          "file_path": "pdfs/rao-et-al-2024-rexerr-synthesizing-clinically-meaningful-errors-in-diagnostic-radiology-reports.pdf"
        },
        {
          "title": "FineRadScore: A Radiology Report Line-by-Line Evaluation Technique Generating Corrections with Severity Scores",
          "authors": [
            {
              "full_name": "Alyssa Huang",
              "normalized_name": "Alyssa Huang"
            },
            {
              "full_name": "Oishi Banerjee",
              "normalized_name": "Oishi Banerjee"
            },
            {
              "full_name": "Kay Wu",
              "normalized_name": "Kay Wu"
            },
            {
              "full_name": "Eduardo Pontes Reis",
              "normalized_name": "Eduardo Reis"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This paper addresses the challenge of evaluating AI-generated chest X-ray (CXR) reports, which traditionally relies on time-consuming radiologist annotations. The authors introduce FineRadScore, an automated evaluation metric leveraging Large Language Models (LLMs) to provide line-by-line corrections and error severity ratings for CXR reports. Empirical results demonstrate that FineRadScore aligns closely with radiologist assessments, outperforming existing automated metrics in both correction accuracy and clinical relevance.",
          "weight": 0.85,
          "role": "primary_research",
          "file_path": "pdfs/2405.20613v2.pdf"
        }
      ]
    },
    {
      "name": "Generalist AI Models Revolutionizing Medical Imaging",
      "synthesis": "The integration of generalist AI models in medical imaging represents a significant advancement in diagnostic capabilities, addressing the limitations of narrow-focused systems. Our work with MedVersa, a generalist learner, demonstrates its ability to outperform specialist models by over 10% across nine diverse tasks, showcasing its versatility in clinical scenarios. Additionally, the large mixture-of-modality-experts model (MOME) for breast cancer diagnosis achieved an AUROC of 0.913, comparable to experienced radiologists, while effectively managing missing data. These innovations complement each other by establishing a framework for robust evaluation, as seen in the ReXrank leaderboard, which highlights the superior performance of generalist models in generating radiology reports. Collectively, these efforts underscore the necessity for adaptive healthcare policies that reflect the comprehensive capabilities of generalist AI tools.",
      "papers": [
        {
          "title": "A Generalist Learner for Multifaceted Medical Image Interpretation",
          "authors": [
            {
              "full_name": "Hong-Yu Zhou, PhD",
              "normalized_name": "Hong Yu Zhou"
            },
            {
              "full_name": "Subathra Adithan, MD",
              "normalized_name": "Subathra Adithan"
            },
            {
              "full_name": "Julián Nicolás Acosta, MD",
              "normalized_name": "Julian Nicolas Acosta"
            },
            {
              "full_name": "Eric J. Topol, MD",
              "normalized_name": "Eric Topol"
            },
            {
              "full_name": "Pranav Rajpurkar, PhD",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This paper addresses the limitation of current medical AI systems, which are often restricted to narrow applications. The key innovation is MedVersa, a generalist learner that utilizes a large language model as a learnable orchestrator to perform flexible medical image interpretation across various clinical scenarios. Empirical results show that MedVersa achieves state-of-the-art performance in nine tasks, often outperforming specialist models by over 10%.",
          "weight": 0.9,
          "role": "primary_research",
          "file_path": "pdfs/2405.07988v1.pdf"
        },
        {
          "title": "Towards Non-invasive and Personalized Management of Breast Cancer Patients from Multiparametric MRI via A Large Mixture-of-Modality-Experts Model",
          "authors": [
            {
              "full_name": "Luyang Luo",
              "normalized_name": "Luyang Luo"
            },
            {
              "full_name": "Mingxiang Wu",
              "normalized_name": "Mingxiang Wu"
            },
            {
              "full_name": "Mei Li",
              "normalized_name": "Mei Li"
            },
            {
              "full_name": "Yi Xin",
              "normalized_name": "Yi Xin"
            },
            {
              "full_name": "Qiong Wang",
              "normalized_name": "Qiong Wang"
            },
            {
              "full_name": "Varut Vardhanabhuti",
              "normalized_name": "Varut Vardhanabhuti"
            },
            {
              "full_name": "Winnie CW Chu",
              "normalized_name": "Winnie CW Chu"
            },
            {
              "full_name": "Zhenhui Li",
              "normalized_name": "Zhenhui Li"
            },
            {
              "full_name": "Juan Zhou",
              "normalized_name": "Juan Zhou"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            },
            {
              "full_name": "Hao Chen",
              "normalized_name": "Hao Chen"
            }
          ],
          "summary": "This paper addresses the challenge of integrating multiparametric MRI data for breast cancer diagnosis, proposing a novel large mixture-of-modality-experts model (MOME) that enhances personalized management of patients. MOME utilizes a comprehensive dataset of 5,205 patients, demonstrating superior performance in malignancy detection with an AUROC of 0.913, comparable to experienced radiologists, while significantly reducing unnecessary biopsies for BI-RADS 4 patients. The model's ability to adapt to missing modalities and provide interpretable results further underscores its clinical utility.",
          "weight": 0.9,
          "role": "primary_research",
          "file_path": "pdfs/2408.12606v2.pdf"
        },
        {
          "title": "ReXrank: A Public Leaderboard for AI-Powered Radiology Report Generation",
          "authors": [
            {
              "full_name": "Xiaoman Zhang",
              "normalized_name": "Xiaoman Zhang"
            },
            {
              "full_name": "Hong-Yu Zhou",
              "normalized_name": "Hongyu Zhou"
            },
            {
              "full_name": "Xiaoli Yang",
              "normalized_name": "Xiaoli Yang"
            },
            {
              "full_name": "Oishi Banerjee",
              "normalized_name": "Oishi Banerjee"
            },
            {
              "full_name": "Julián N. Acosta",
              "normalized_name": "Julian Acosta"
            },
            {
              "full_name": "Josh Miller",
              "normalized_name": "Josh Miller"
            },
            {
              "full_name": "Ouwen Huang",
              "normalized_name": "Ouwen Huang"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This paper addresses the lack of standardized benchmarks for evaluating AI-driven radiology report generation models, particularly for chest X-rays. The authors introduce ReXrank, a public leaderboard that utilizes a comprehensive evaluation framework incorporating diverse datasets and multiple evaluation metrics to assess model performance. Key findings indicate that MedVersa outperforms other models across various datasets, demonstrating the effectiveness of the proposed evaluation framework in providing insights into model robustness and generalization capabilities.",
          "weight": 0.9,
          "role": "primary_research",
          "file_path": "pdfs/2411.15122v1.pdf"
        },
        {
          "title": "Reimbursement in the age of generalist radiology artificial intelligence",
          "authors": [
            {
              "full_name": "Siddhant Dogra",
              "normalized_name": "Siddhant Dogra"
            },
            {
              "full_name": "Ezequiel Silva III",
              "normalized_name": "Ezequiel Silva"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This paper addresses the challenge of integrating generalist radiology artificial intelligence (GRAI) into existing healthcare reimbursement frameworks, which are primarily designed for narrow AI tools. The authors propose that GRAI's multi-task capabilities necessitate a reevaluation of coding, valuation, and coverage policies to facilitate its adoption. Empirical findings suggest that GRAI tools, such as MedVersa, outperform specialized models, indicating a need for adaptive reimbursement strategies that reflect their comprehensive functionality.",
          "weight": 0.8,
          "role": "primary_research",
          "file_path": "pdfs/s41746-024-01352-w.pdf"
        },
        {
          "title": "The MAIDA initiative: establishing a framework for global medical-imaging data sharing",
          "authors": [
            {
              "full_name": "Agustina Saenz",
              "normalized_name": "Agustina Saenz"
            },
            {
              "full_name": "Emma Chen",
              "normalized_name": "Emma Chen"
            },
            {
              "full_name": "Henrik Marklund",
              "normalized_name": "Henrik Marklund"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "The MAIDA initiative addresses the critical research problem of insufficient diversity in public datasets for training AI models in medical imaging, which affects their generalizability across diverse populations. The key innovation is a collaborative framework for global medical-imaging data sharing that enables the collection of diverse datasets, facilitating rigorous evaluation of AI models. Preliminary findings indicate that engaging local champions and standardizing data-sharing protocols can significantly enhance data collection efficiency and quality, although challenges in institutional compliance remain.",
          "weight": 0.8,
          "role": "primary_research",
          "file_path": "pdfs/PIIS2589750023002224.pdf"
        },
        {
          "title": "Evaluating General Vision-Language Models for Clinical Medicine",
          "authors": [
            {
              "full_name": "Yixing Jiang",
              "normalized_name": "Yixing Jiang"
            },
            {
              "full_name": "Jesutofunmi A. Omiye",
              "normalized_name": "Jesutofunmi Omiye"
            },
            {
              "full_name": "Cyril Zakka",
              "normalized_name": "Cyril Zakka"
            },
            {
              "full_name": "Michael Moor",
              "normalized_name": "Michael Moor"
            },
            {
              "full_name": "Haiwen Gui",
              "normalized_name": "Haiwen Gui"
            },
            {
              "full_name": "Shayan Alipour",
              "normalized_name": "Shayan Alipour"
            },
            {
              "full_name": "Seyed Shahabeddin Mousavi",
              "normalized_name": "Seyed Shahabeddin Mousavi"
            },
            {
              "full_name": "Jonathan H. Chen",
              "normalized_name": "Jonathan Chen"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            },
            {
              "full_name": "Roxana Daneshjou",
              "normalized_name": "Roxana Daneshjou"
            }
          ],
          "summary": "This paper addresses the limitations of large multimodal models (LMMs) like GPT-4V in clinical medicine, particularly in gastroenterology, radiology, and dermatology. The authors benchmarked GPT-4V's diagnostic capabilities using robust datasets and found significant performance deficits compared to existing models, with macro-average precision, recall, and F1-scores as low as 6.8% in gastroenterology. The study highlights the model's challenges in accurately diagnosing conditions across diverse skin tones, emphasizing the need for improved methodologies in AI-assisted medical diagnostics.",
          "weight": 0.3,
          "role": "primary_research",
          "file_path": "pdfs/2024.04.12.24305744v2.full.pdf"
        }
      ]
    },
    {
      "name": "Innovative Evaluation Metrics for AI-Generated Radiology Reports",
      "synthesis": "The evaluation of AI-generated radiology reports is critical for ensuring their reliability and effectiveness in clinical practice. We introduced the ReXamine-Global framework, which demonstrated significant gaps in the generalizability of established metrics, revealing that a GPT-4-based metric outperformed others in aligning with expert evaluations. Our work on ReXKG further advanced this area by developing novel metrics that assess AI models' understanding of radiological images, highlighting the limitations of generalist models in capturing detailed medical information. Additionally, the ReXplain system showcased the potential of integrating language models and image segmentation to enhance patient comprehension of radiology reports, thereby improving patient engagement. Collectively, these innovations underscore the importance of tailored evaluation methodologies that address both technical performance and user-centric outcomes.",
      "papers": [
        {
          "title": "ReXamine-Global: A Framework for Uncovering Inconsistencies in Radiology Report Generation Metrics",
          "authors": [
            {
              "full_name": "Oishi Banerjee",
              "normalized_name": "Oishi Banerjee"
            },
            {
              "full_name": "Agustina Saenz",
              "normalized_name": "Agustina Saenz"
            },
            {
              "full_name": "Kay Wu",
              "normalized_name": "Kay Wu"
            },
            {
              "full_name": "Warren Clements",
              "normalized_name": "Warren Clements"
            },
            {
              "full_name": "Adil Zia",
              "normalized_name": "Adil Zia"
            },
            {
              "full_name": "Dominic Buensalido",
              "normalized_name": "Dominic Buensalido"
            },
            {
              "full_name": "Helen Kavnoudias",
              "normalized_name": "Helen Kavnoudias"
            },
            {
              "full_name": "Alain S. Abi-Ghanem",
              "normalized_name": "Alain Abi-Ghanem"
            },
            {
              "full_name": "Nour El Ghawi",
              "normalized_name": "Nour El Ghawi"
            },
            {
              "full_name": "Cibele Luna",
              "normalized_name": "Cibele Luna"
            },
            {
              "full_name": "Patricia Castillo",
              "normalized_name": "Patricia Castillo"
            },
            {
              "full_name": "Khaled Al-Surimi",
              "normalized_name": "Khaled Al-Surimi"
            },
            {
              "full_name": "Rayyan A. Daghistani",
              "normalized_name": "Rayyan Daghistani"
            },
            {
              "full_name": "Yuh-Min Chen",
              "normalized_name": "Yuh-Min Chen"
            },
            {
              "full_name": "Heng-sheng Chao",
              "normalized_name": "Heng-sheng Chao"
            },
            {
              "full_name": "Lars Heiliger",
              "normalized_name": "Lars Heiliger"
            },
            {
              "full_name": "Moon Kim",
              "normalized_name": "Moon Kim"
            },
            {
              "full_name": "Johannes Haubold",
              "normalized_name": "Johannes Haubold"
            },
            {
              "full_name": "Frederic Jonske",
              "normalized_name": "Frederic Jonske"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "The paper addresses the challenge of evaluating AI-generated radiology reports across diverse hospitals, highlighting the inadequacy of existing metrics in measuring report quality. The key innovation is the ReXamine-Global framework, which assesses the generalizability of evaluation metrics by testing their sensitivity to reporting styles and their agreement with expert evaluations. Empirical findings reveal significant gaps in the generalizability of seven established metrics, with a GPT-4-based metric demonstrating superior performance.",
          "weight": 0.85,
          "role": "primary_research",
          "file_path": "pdfs/banerjee-et-al-2024-rexamine-global-a-framework-for-uncovering-inconsistencies-in-radiology-report-generation-metrics.pdf"
        },
        {
          "title": "A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges",
          "authors": [
            {
              "full_name": "Zifeng Wang",
              "normalized_name": "Zifeng Wang"
            },
            {
              "full_name": "Hanyin Wang",
              "normalized_name": "Hanyin Wang"
            },
            {
              "full_name": "Benjamin Danek",
              "normalized_name": "Benjamin Danek"
            },
            {
              "full_name": "Ying Li",
              "normalized_name": "Ying Li"
            },
            {
              "full_name": "Christina Mack",
              "normalized_name": "Christina Mack"
            },
            {
              "full_name": "Luk Arbuckle",
              "normalized_name": "Luk Arbuckle"
            },
            {
              "full_name": "Devyani Biswal",
              "normalized_name": "Devyani Biswal"
            },
            {
              "full_name": "Hoifung Poon",
              "normalized_name": "Hoifung Poon"
            },
            {
              "full_name": "Yajuan Wang",
              "normalized_name": "Yajuan Wang"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            },
            {
              "full_name": "Jimeng Sun",
              "normalized_name": "Jimeng Sun"
            }
          ],
          "summary": "This paper addresses the challenge of adapting generalist Large Language Models (LLMs) for specialized medical applications. The authors propose a three-step framework for developing medical AI applications, which includes modeling complex workflows, optimizing model performance, and system engineering for task decomposition. Key findings highlight the importance of domain-specific adaptations to improve accuracy and reliability in high-stakes medical contexts, emphasizing the need for robust methodologies to mitigate issues like hallucinations and ensure compliance with medical standards.",
          "weight": 0.85,
          "role": "primary_research",
          "file_path": "pdfs/2411.00024v3.pdf"
        },
        {
          "title": "Implications of Race Adjustment in Lung-Function Equations",
          "authors": [
            {
              "full_name": "James A. Diao",
              "normalized_name": "Diao James"
            },
            {
              "full_name": "Yixuan He",
              "normalized_name": "He Yixuan"
            },
            {
              "full_name": "Rohan Khazanchi",
              "normalized_name": "Khazanchi Rohan"
            },
            {
              "full_name": "Max Jordan Nguemeni Tiako",
              "normalized_name": "Tiako Max Nguemeni"
            },
            {
              "full_name": "Jonathan I. Witonsky",
              "normalized_name": "Witonsky Jonathan"
            },
            {
              "full_name": "Emma Pierson",
              "normalized_name": "Pierson Emma"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Rajpurkar Pranav"
            },
            {
              "full_name": "Jennifer R. Elhawary",
              "normalized_name": "Elhawary Jennifer"
            },
            {
              "full_name": "Luke Melas-Kyriazi",
              "normalized_name": "Melas-Kyriazi Luke"
            },
            {
              "full_name": "Albert Yen",
              "normalized_name": "Yen Albert"
            },
            {
              "full_name": "Alicia R. Martin",
              "normalized_name": "Martin Alicia"
            },
            {
              "full_name": "Sean Levy",
              "normalized_name": "Levy Sean"
            },
            {
              "full_name": "Chirag J. Patel",
              "normalized_name": "Patel Chirag"
            },
            {
              "full_name": "Maha Farhat",
              "normalized_name": "Farhat Maha"
            },
            {
              "full_name": "Luisa N. Borrell",
              "normalized_name": "Borrell Luisa"
            },
            {
              "full_name": "Michael H. Cho",
              "normalized_name": "Cho Michael"
            },
            {
              "full_name": "Edwin K. Silverman",
              "normalized_name": "Silverman Edwin"
            },
            {
              "full_name": "Esteban G. Burchard",
              "normalized_name": "Burchard Esteban"
            },
            {
              "full_name": "Arjun K. Manrai",
              "normalized_name": "Manrai Arjun"
            }
          ],
          "summary": "This study addresses the implications of using race-adjusted versus race-neutral lung-function equations in clinical practice. The key innovation is the comparison of the 2012 Global Lung Function Initiative (GLI-2012) equations with the newly introduced race-neutral GLI-Global equations, utilizing data from over 369,000 participants. The findings reveal significant reclassifications in lung disease diagnoses and disability compensation, with potential impacts on millions of individuals, particularly highlighting disparities in outcomes based on race. The study suggests that while both equations maintain similar predictive accuracy for respiratory outcomes, the choice of equation can lead to vastly different clinical and financial implications.",
          "weight": 0.85,
          "role": "primary_research",
          "file_path": "pdfs/nihms-2003202.pdf"
        },
        {
          "title": "Randomised controlled trials evaluating artificial intelligence in clinical practice: a scoping review",
          "authors": [
            {
              "full_name": "Ryan Han",
              "normalized_name": "Ryan Han"
            },
            {
              "full_name": "Julián N Acosta",
              "normalized_name": "Julian Acosta"
            },
            {
              "full_name": "Zahra Shakeri",
              "normalized_name": "Zahra Shakeri"
            },
            {
              "full_name": "John P A Ioannidis",
              "normalized_name": "John Ioannidis"
            },
            {
              "full_name": "Eric J Topol",
              "normalized_name": "Eric Topol"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This scoping review addresses the research problem of evaluating the effectiveness of artificial intelligence (AI) in clinical practice through randomized controlled trials (RCTs). The key innovation is the systematic analysis of 86 RCTs, revealing that 81% reported positive primary endpoints, primarily in diagnostic yield and performance, although concerns about generalizability and publication bias were noted. The findings emphasize the need for more multicenter trials and diverse outcome measures to better understand AI's impact on healthcare.",
          "weight": 0.8,
          "role": "primary_research",
          "file_path": "pdfs/PIIS2589750024000475.pdf"
        },
        {
          "title": "Uncovering Knowledge Gaps in Radiology Report Generation Models through Knowledge Graphs",
          "authors": [
            {
              "full_name": "Xiaoman Zhang",
              "normalized_name": "Xiaoman Zhang"
            },
            {
              "full_name": "Julián N. Acosta",
              "normalized_name": "Julian Acosta"
            },
            {
              "full_name": "Hong-Yu Zhou",
              "normalized_name": "Hongyu Zhou"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This paper addresses the limitations of existing evaluation methods for AI-generated radiology reports, which fail to capture the models' understanding of radiological images. The authors introduce ReXKG, a system that constructs a comprehensive radiology knowledge graph and propose three novel metrics to evaluate AI models' performance. The study reveals that while generalist models show broader coverage of essential entities, they still lack the depth and detail found in human-written reports, particularly in describing medical devices and providing quantified measurements.",
          "weight": 0.8,
          "role": "primary_research",
          "file_path": "pdfs/2408.14397v1.pdf"
        },
        {
          "title": "ReXplain: Translating Radiology into Patient-Friendly Video Reports",
          "authors": [
            {
              "full_name": "Luyang Luo",
              "normalized_name": "Luyang Luo"
            },
            {
              "full_name": "Jenanan Vairavamurthy",
              "normalized_name": "Jenanan Vairavamurthy"
            },
            {
              "full_name": "Xiaoman Zhang",
              "normalized_name": "Xiaoman Zhang"
            },
            {
              "full_name": "Abhinav Kumar",
              "normalized_name": "Abhinav Kumar"
            },
            {
              "full_name": "Ramon R. Ter-Oganesyan",
              "normalized_name": "Ramon Ter-Oganesyan"
            },
            {
              "full_name": "Stuart T. Schroff",
              "normalized_name": "Stuart Schroff"
            },
            {
              "full_name": "Dan Shilo",
              "normalized_name": "Dan Shilo"
            },
            {
              "full_name": "Rydhwana Hossain",
              "normalized_name": "Rydhwana Hossain"
            },
            {
              "full_name": "Mike Moritz",
              "normalized_name": "Mike Moritz"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This paper addresses the challenge of making radiology reports comprehensible to patients, who often struggle with complex medical terminology. The key innovation is the ReXplain system, which integrates a large language model for text simplification, an image segmentation model for anatomical identification, and an avatar for delivering explanations. Empirical findings from a proof-of-concept study with five radiologists indicate that ReXplain effectively conveys radiological information and simulates one-on-one consultations, potentially enhancing patient engagement and satisfaction.",
          "weight": 0.8,
          "role": "primary_research",
          "file_path": "pdfs/2410.00441v1.pdf"
        }
      ]
    },
    {
      "name": "Synthetic Data Generation Enhancing Medical Imaging Models",
      "synthesis": "The significance of synthetic data generation in enhancing medical imaging models cannot be overstated, as it addresses critical challenges such as data scarcity and privacy concerns. Our exploration of generative models, particularly GANs and diffusion models, has demonstrated that synthetic data can substantially improve classification and segmentation performance, with empirical results indicating accuracy enhancements when synthetic images are integrated with real data. Additionally, the introduction of video pretraining has shown remarkable improvements in 3D model performance on chest CT tasks, achieving AUC metric increases of up to 0.182 in PE detection. We also established that multimodal image-text matching techniques, like X-REM, significantly enhance the coherence and relevance of radiology reports, evidenced by a 70% increase in zero-error reports. Collectively, these methodologies not only complement each other but also pave the way for more robust and clinically applicable AI solutions in medical imaging.",
      "papers": [
        {
          "title": "Video Pretraining Advances 3D Deep Learning on Chest CT Tasks",
          "authors": [
            {
              "full_name": "Alexander Ke",
              "normalized_name": "Alexander Ke"
            },
            {
              "full_name": "Shih-Cheng Huang",
              "normalized_name": "Shih Cheng Huang"
            },
            {
              "full_name": "Chloe O’Connell",
              "normalized_name": "Chloe OConnell"
            },
            {
              "full_name": "Micha l Klimont",
              "normalized_name": "Micha l Klimont"
            },
            {
              "full_name": "Serena Yeung",
              "normalized_name": "Serena Yeung"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This study addresses the challenge of limited data in 3D medical imaging tasks by exploring the effectiveness of video pretraining for 3D models. The key innovation is the application of large-scale video datasets to enhance model performance on chest CT tasks, demonstrating that video pretraining consistently improves the performance of 3D models over traditional 2D baselines. Empirical results show significant increases in AUC metrics, with improvements of up to 0.182 in PE detection tasks when using video pretraining compared to in-domain CT pretraining.",
          "weight": 0.9,
          "role": "primary_research",
          "file_path": "pdfs/ke24a.pdf"
        },
        {
          "title": "Generating Synthetic Data for Medical Imaging",
          "authors": [
            {
              "full_name": "Lennart R. Koetzier",
              "normalized_name": "Koetzier Lennart"
            },
            {
              "full_name": "Jie Wu",
              "normalized_name": "Wu Jie"
            },
            {
              "full_name": "Domenico Mastrodicasa",
              "normalized_name": "Mastrodicasa Domenico"
            },
            {
              "full_name": "Aline Lutz",
              "normalized_name": "Lutz Aline"
            },
            {
              "full_name": "Matthew Chung",
              "normalized_name": "Chung Matthew"
            },
            {
              "full_name": "W. Adam Koszek",
              "normalized_name": "Koszek Adam"
            },
            {
              "full_name": "Jayanth Pratap",
              "normalized_name": "Pratap Jayanth"
            },
            {
              "full_name": "Akshay S. Chaudhari",
              "normalized_name": "Chaudhari Akshay"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Rajpurkar Pranav"
            },
            {
              "full_name": "Matthew P. Lungren",
              "normalized_name": "Lungren Matthew"
            },
            {
              "full_name": "Martin J. Willemink",
              "normalized_name": "Willemink Martin"
            }
          ],
          "summary": "This paper addresses the challenge of data scarcity and privacy issues in medical imaging, which hinder the development of AI models. The authors propose the use of synthetic data generated by AI models as a solution, highlighting advancements in generative models such as GANs and diffusion models. Empirical findings indicate that synthetic data can significantly enhance the performance of AI models in classification and segmentation tasks, with quantitative results showing improved accuracy when synthetic images are used alongside real data.",
          "weight": 0.85,
          "role": "primary_research",
          "file_path": "pdfs/koetzier-et-al-2024-generating-synthetic-data-for-medical-imaging.pdf"
        },
        {
          "title": "Direct Preference Optimization for Suppressing Hallucinated Prior Exams in Radiology Report Generation",
          "authors": [
            {
              "full_name": "Oishi Banerjee",
              "normalized_name": "Oishi Banerjee"
            },
            {
              "full_name": "Hong-Yu Zhou",
              "normalized_name": "Hong Yu Zhou"
            },
            {
              "full_name": "Subathra Adithan",
              "normalized_name": "Subathra Adithan"
            },
            {
              "full_name": "Stephen Kwak",
              "normalized_name": "Stephen Kwak"
            },
            {
              "full_name": "Kay Wu",
              "normalized_name": "Kay Wu"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This paper addresses the problem of hallucinations in generative vision-language models (VLMs) used for radiology report generation, specifically the hallucination of prior exams. The authors introduce a direct preference optimization (DPO) method that effectively reduces these hallucinations by fine-tuning pretrained VLMs, achieving a 3.2-4.8x reduction in lines hallucinating prior exams while maintaining clinical accuracy metrics. This work is significant as it is the first to apply DPO to medical VLMs, providing a practical solution to a critical issue in AI-assisted radiology.",
          "weight": 0.85,
          "role": "primary_research",
          "file_path": "pdfs/2406.06496v2.pdf"
        },
        {
          "title": "Multimodal Image-Text Matching Improves Retrieval-based Chest X-Ray Report Generation",
          "authors": [
            {
              "full_name": "Jaehwan Jeong",
              "normalized_name": "Jaehwan Jeong"
            },
            {
              "full_name": "Katherine Tian",
              "normalized_name": "Katherine Tian"
            },
            {
              "full_name": "Andrew Li",
              "normalized_name": "Andrew Li"
            },
            {
              "full_name": "Sina Hartung",
              "normalized_name": "Sina Hartung"
            },
            {
              "full_name": "Fardad Behzadi",
              "normalized_name": "Fardad Behzadi"
            },
            {
              "full_name": "Juan Calle",
              "normalized_name": "Juan Calle"
            },
            {
              "full_name": "David Osayande",
              "normalized_name": "David Osayande"
            },
            {
              "full_name": "Michael Pohlen",
              "normalized_name": "Michael Pohlen"
            },
            {
              "full_name": "Subathra Adithan",
              "normalized_name": "Subathra Adithan"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This paper addresses the challenge of generating clinically accurate radiology reports from chest X-ray images, which often suffer from incoherence and irrelevance in existing methods. The authors introduce Contrastive X-Ray REport Match (X-REM), a novel retrieval-based approach that utilizes an image-text matching score to enhance report retrieval accuracy. Empirical results demonstrate that X-REM significantly outperforms prior models, achieving higher clinical and natural language metrics, and increasing the number of zero-error reports by 70%.",
          "weight": 0.85,
          "role": "primary_research",
          "file_path": "pdfs/jeong24a.pdf"
        },
        {
          "title": "Adapting Segment Anything Models to Medical Imaging via Fine-Tuning without Domain Pretraining",
          "authors": [
            {
              "full_name": "Kevin Li",
              "normalized_name": "Kevin Li"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This paper addresses the challenge of adapting the Segment Anything Model (SAM) for medical image segmentation without relying on domain-specific pre-training. The authors introduce a novel fine-tuning method called LoRaMedNet, which combines Low-Rank Adaptation with a ConvNet prediction head, demonstrating that SAM can achieve superior performance on medical tasks compared to MedSAM, a model specifically trained on medical datasets. Empirical results show that LoRaMedNet-adapted SAM outperforms existing methods, achieving an average Dice score of 85.34, indicating its effectiveness in medical image segmentation tasks.",
          "weight": 0.8,
          "role": "primary_research",
          "file_path": "pdfs/22_Adapting_Segment_Anything_M.pdf"
        }
      ]
    },
    {
      "name": "Addressing Hallucinations and Uncertainty in AI Systems",
      "synthesis": "Addressing hallucinations and uncertainty in AI systems is crucial for enhancing the reliability of clinical decision-making, particularly in radiology. We introduced FactCheXcker, a modular framework that significantly mitigates measurement hallucinations, achieving a 94% improvement in measurement accuracy across various models. Our work on uncertainty quantification revealed poor calibration in existing models, emphasizing the need for advanced methods to ensure trustworthy predictions. By integrating insights from diverse studies, such as the comparative analysis of AI and human performance, we highlight the complementary roles of AI and clinicians in improving diagnostic outcomes. Collectively, these innovations pave the way for more effective and reliable AI applications in medical imaging.",
      "papers": [
        {
          "title": "FactCheXcker: Mitigating Measurement Hallucinations in Chest X-ray Report Generation Models",
          "authors": [
            {
              "full_name": "Alice Heiman",
              "normalized_name": "Alice Heiman"
            },
            {
              "full_name": "Xiaoman Zhang, PhD",
              "normalized_name": "Xiaoman Zhang"
            },
            {
              "full_name": "Emma Chen, MS",
              "normalized_name": "Emma Chen"
            },
            {
              "full_name": "Sung Eun Kim, MD",
              "normalized_name": "Sung Eun Kim"
            },
            {
              "full_name": "Pranav Rajpurkar, PhD",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This paper addresses the challenge of measurement hallucinations in radiology report generation models, which can lead to inaccurate clinical assessments. The authors introduce FactCheXcker, a modular framework that utilizes a query-code-update paradigm to enhance measurement accuracy by generating specific measurement queries and executing code to retrieve precise measurements. Empirical results demonstrate that FactCheXcker significantly reduces hallucinations, achieving an average improvement of 94% in measurement accuracy across multiple models evaluated on the MIMIC-CXR dataset.",
          "weight": 0.9,
          "role": "primary_research",
          "file_path": "pdfs/2411.18672v1.pdf"
        },
        {
          "title": "Heterogeneity and predictors of the effects of AI assistance on radiologists",
          "authors": [
            {
              "full_name": "Feiyang Yu",
              "normalized_name": "Feiyang Yu"
            },
            {
              "full_name": "Alex Moehring",
              "normalized_name": "Alex Moehring"
            },
            {
              "full_name": "Oishi Banerjee",
              "normalized_name": "Oishi Banerjee"
            },
            {
              "full_name": "Tobias Salz",
              "normalized_name": "Tobias Salz"
            },
            {
              "full_name": "Nikhil Agarwal",
              "normalized_name": "Nikhil Agarwal"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This study addresses the heterogeneous effects of AI assistance on 140 radiologists performing 15 chest X-ray diagnostic tasks. The key innovation lies in identifying that conventional experience-based factors do not reliably predict the impact of AI assistance, and that AI errors significantly influence treatment outcomes. The findings reveal a treatment effect range from -1.295 to 1.440, emphasizing the need for personalized approaches in clinician-AI collaboration.",
          "weight": 0.85,
          "role": "primary_research",
          "file_path": "pdfs/s41591-024-02850-w.pdf"
        },
        {
          "title": "Pixels and Pitfalls: Building Robust Artificial Intelligence for Medical Imaging",
          "authors": [
            {
              "full_name": "Pranav Rajpurkar, Ph.D.",
              "normalized_name": "Pranav Rajpurkar"
            },
            {
              "full_name": "Andrew L. Beam, Ph.D.",
              "normalized_name": "Andrew Beam"
            },
            {
              "full_name": "Arjun K. Manrai, Ph.D.",
              "normalized_name": "Arjun Manrai"
            }
          ],
          "summary": "This paper addresses the challenges and advancements in artificial intelligence (AI) applications for medical imaging, particularly focusing on the evolution from early models like CheXNet to more advanced systems such as CheXzero. The key innovation lies in the development of AI models that can interpret medical images without explicit labels, emphasizing the importance of understanding the data generation process to avoid biases. The findings highlight the necessity for open access to medical data and the collaborative role of clinicians in guiding AI development, with a vision for future AI systems that enhance clinical decision-making and patient outcomes.",
          "weight": 0.85,
          "role": "primary_research",
          "file_path": "pdfs/AIp2400803.pdf"
        },
        {
          "title": "Calibration and Uncertainty Estimation Challenges in Self-Supervised Chest X-ray Pathology Classification Models",
          "authors": [
            {
              "full_name": "Jenny Xu",
              "normalized_name": "Jenny Xu"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            }
          ],
          "summary": "This paper addresses the critical issue of uncertainty quantification in AI systems for clinical radiology, specifically focusing on the calibration of the CheXzero model for chest X-ray pathology detection. The authors evaluate the model's performance on two external datasets using Maximum Softmax Probabilities (MSP) and Monte Carlo Dropout methods, revealing poor calibration with Expected Calibration Error (ECE) scores ranging from 0.12 to 0.41, and a lack of correlation between prediction accuracy and uncertainty scores. These findings underscore the necessity for improved uncertainty quantification methods in AI-assisted clinical decision-making.",
          "weight": 0.8,
          "role": "primary_research",
          "file_path": "pdfs/160_Calibration_and_Uncertaint.pdf"
        },
        {
          "title": "Comparative Advantage of Humans vs AI in the Long Tail",
          "authors": [
            {
              "full_name": "Nikhil Agarwal",
              "normalized_name": "Nikhil Agarwal"
            },
            {
              "full_name": "Ray Huang",
              "normalized_name": "Ray Huang"
            },
            {
              "full_name": "Alex Moehring",
              "normalized_name": "Alex Moehring"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            },
            {
              "full_name": "Tobias Salz",
              "normalized_name": "Tobias Salz"
            },
            {
              "full_name": "Feiyang Yu",
              "normalized_name": "Feiyang Yu"
            }
          ],
          "summary": "This paper addresses the research problem of whether zero-shot learning algorithms diminish the advantage of human radiologists in diagnosing rare diseases. The key innovation is the comparison of the performance of CheXzero, a zero-shot learning algorithm, against human radiologists and CheXpert, a traditional supervised learning algorithm, across 79 diseases. The findings indicate that while humans still outperform CheXzero on select pathologies, the AI's performance is significantly higher overall, suggesting that AI may surpass human capabilities in the long tail of diseases.",
          "weight": 0.8,
          "role": "primary_research",
          "file_path": "pdfs/ComparativeAdvantageOfHumansVsAIIn_preview.pdf"
        },
        {
          "title": "Cell morphological representations of genes enhance prediction of drug targets",
          "authors": [
            {
              "full_name": "Niveditha S. Iyer",
              "normalized_name": "Niveditha Iyer"
            },
            {
              "full_name": "Daniel J. Michael",
              "normalized_name": "Daniel Michael"
            },
            {
              "full_name": "S-Y Gordon Chi",
              "normalized_name": "S-Y Chi"
            },
            {
              "full_name": "John Arevalo",
              "normalized_name": "John Arevalo"
            },
            {
              "full_name": "Srinivas Niranj Chandrasekaran",
              "normalized_name": "Srinivas Chandrasekaran"
            },
            {
              "full_name": "Anne E. Carpenter",
              "normalized_name": "Anne Carpenter"
            },
            {
              "full_name": "Pranav Rajpurkar",
              "normalized_name": "Pranav Rajpurkar"
            },
            {
              "full_name": "Shantanu Singh",
              "normalized_name": "Shantanu Singh"
            }
          ],
          "summary": "This study addresses the challenge of identifying potential protein targets for candidate drugs in the drug discovery process. The key innovation is the integration of gene morphological profiles into a transformer-based machine learning model, which significantly improves the prediction accuracy of gene-compound interactions. Empirical results show that the model outperforms baseline methods, particularly in predicting targets for previously unseen compounds, indicating a promising approach for accelerating drug discovery.",
          "weight": 0.8,
          "role": "primary_research",
          "file_path": "pdfs/2024.06.08.598076v1.full.pdf"
        }
      ]
    }
  ]
}